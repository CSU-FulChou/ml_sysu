{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 作业02：Fashion Mnist实现图像分类\n",
    "\n",
    "## 1 概述\n",
    "Fashion-MNIST是一个替代MNIST手写数字集的图像数据集，它是由Zalando（一家德国的时尚科技公司）旗下的研究部门提供。其涵盖了来自10种类别的共7万个不同商品的正面图片。Fashion-MNIST的大小、格式和训练集/测试集划分与原始的MNIST完全一致。数据集按照60000/10000的比例进行训练测试数据划分，全部数据均为28x28的灰度图片。\n",
    "\n",
    "**基本要求**：\n",
    "1. 使用卷积神经网络完成Fashion-MNIST的分类任务。\n",
    "2. 在README文件中描述所使用的模型的结构、优化器、损失函数和超参数等信息，以及模型在训练集和测试集上的最优结果。\n",
    "3. 对模型中训练过程损失函数的变化趋势可视化\n",
    "\n",
    "**加分项**：可以对模型进行优化（包括增加层数，使用残差连接，调整超参数等），或者对模型的训练过程/结果进行可视化（例如模型损失函数在训练过程中的变化趋势，或者参数的分布随训练批次的变化趋势等）。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. 实现模型\n",
    "\n",
    "### 2.1 数据集加载\n",
    "可以通过飞桨自带的`paddle.vision.dataset`进行数据集加载，并且通过`paddle.vision.transforms`对数据进行预处理，例如对数据进行归一化。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import paddle\n",
    "print(paddle.__version__)\n",
    "\n",
    "import paddle.vision.transforms as T\n",
    "\n",
    "transform = T.Compose([T.Normalize(mean=[127.5],\n",
    "                                   std=[127.5],\n",
    "                                   data_format='CHW')])\n",
    "\n",
    "# 对数据进行归一化\n",
    "train_dataset = paddle.vision.datasets.FashionMNIST(mode='train', transform=transform)\n",
    "test_dataset = paddle.vision.datasets.FashionMNIST(mode='test', transform=transform)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.1.2\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 模型搭建\n",
    "\n",
    "使用paddle的接口搭建神经网络模型。以LeNet模型为例，该模型与1998年提出，包含了深度学习图像处理相关的基本模块。\n",
    "\n",
    "LeNet模型一共有7层，包括2个**卷积层**，2个**池化层**和3个**全连接层**。通过连续使用卷积层和池化层提取图像特征。Paddle中提供了相应的接口，可以快速搭建网络模型：\n",
    "1. 卷积层：`paddle.nn.Conv2D`；\n",
    "2. 池化层：`paddle.nn.MaxPool2D`；\n",
    "3. 全连接层：`paddle.nn.Linear`。\n",
    "\n",
    "### **作业要求**：搭建神经网络，完成`__init__`和`forward`函数，并在README文件中详细描述所使用模型的信息。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MyNet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "import paddle.nn.functional as F\n",
    "import paddle.nn as NN\n",
    "class MyNet(paddle.nn.Layer):    \n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.layer1 = NN.Sequential(   \n",
    "            NN.Conv2D(1, 16, kernel_size=5, padding=2),\n",
    "            NN.BatchNorm2D(16), \n",
    "            NN.ReLU()) #16, 28, 28\n",
    "        self.pool1=NN.MaxPool2D(2) #16, 14, 14\n",
    "        self.layer2 = NN.Sequential(\n",
    "            NN.Conv2D(16, 32, kernel_size=3),\n",
    "            NN.BatchNorm2D(32),\n",
    "            NN.ReLU())#32, 12, 12\n",
    "        self.layer3 = NN.Sequential(\n",
    "            NN.Conv2D(32, 64, kernel_size=3),\n",
    "            NN.BatchNorm2D(64),\n",
    "            NN.ReLU()) #64, 10, 10\n",
    "        self.pool2=NN.MaxPool2D(2)  #64, 5, 5\n",
    "        self.fc = NN.Linear(5*5*64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        #print(out.shape)\n",
    "        out=self.pool1(out)\n",
    "        #print(out.shape)\n",
    "        out = self.layer2(out)\n",
    "        #print(out.shape)\n",
    "        out=self.layer3(out)\n",
    "        #print(out.shape)\n",
    "        out=self.pool2(out)\n",
    "        # print(out.shape)\n",
    "        out = paddle.reshape(out,[-1,5*5*64])\n",
    "        #print(out.shape)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# resnet18"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "# 首先实现中间两个卷积层，Skip Connection 1x1 卷积层的残差模块。代码如下：\n",
    "# 残差模块\n",
    "class Residual(nn.Layer):\n",
    "    def __init__(self, in_channel, out_channel, use_conv1x1=False, stride=1):\n",
    "        super(Residual, self).__init__()\n",
    "        \n",
    "        # 第一个卷积单元\n",
    "        self.conv1 = nn.Conv2D(in_channel, out_channel, kernel_size=3, padding=1, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm2D(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # 第二个卷积单元\n",
    "        self.conv2 = nn.Conv2D(out_channel, out_channel, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2D(out_channel)\n",
    "\n",
    "        if use_conv1x1: #使用1x1卷积核完成shape匹配,stride=2实现下采样\n",
    "            self.skip = nn.Conv2D(in_channel, out_channel, kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.skip = None\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向计算\n",
    "        # [b, c, h, w], 通过第一个卷积单元\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        # 通过第二个卷积单元\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        #  通过 identity 模块\n",
    "        if self.skip:\n",
    "            x = self.skip(x)\n",
    "        #  2 条路径输出直接相加,然后输入激活函数\n",
    "        output = F.relu(out + x)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "# 通过build_resblock 可以一次完成2个残差模块的创建。代码如下：\n",
    "def build_resblock(in_channel, out_channel, num_layers, is_first=False):\n",
    "    if is_first:\n",
    "        assert in_channel == out_channel\n",
    "    block_list = []\n",
    "    for i in range(num_layers):\n",
    "        if i == 0 and not is_first:\n",
    "            block_list.append(Residual(in_channel, out_channel, use_conv1x1=True, stride=2))\n",
    "        else:\n",
    "            block_list.append(Residual(out_channel, out_channel))\n",
    "    resNetBlock = nn.Sequential(*block_list) #用*号可以把list列表展开为元素\n",
    "    return resNetBlock\n",
    "\n",
    "# 下面来实现ResNet18网络模型。代码如下：\n",
    "class ResNet18_1(nn.Layer):\n",
    "    # 继承paddle.nn.Layer定义网络结构\n",
    "    def __init__(self,num_classes=10):\n",
    "        super(ResNet18_1, self).__init__()\n",
    "        # 初始化函数(根网络，预处理)\n",
    "        # x:[b, c, h ,w]=[b,3,224,224]\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2D(in_channels=1, out_channels=64, kernel_size=7, \n",
    "            stride=2, padding=3),# 第一层卷积,x:[b,64,112,112]\n",
    "            nn.BatchNorm2D(64),# 归一化层\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2D(kernel_size=3, stride=2, padding=1)# 最大池化，下采样,x:[b,64,56,56]\n",
    "        )\n",
    "        \n",
    "        # 堆叠 4 个 Block，每个 block 包含了多个残差模块,设置步长不一样\n",
    "        self.layer1 = build_resblock(64, 64, 2, is_first=True) # x:[b,64,56,56]\n",
    "        self.layer2 = build_resblock(64, 150, 2) # x:[b,150,28,28]\n",
    "        self.layer3 = build_resblock(150, 360, 2)  # x:[b,360,14,14]\n",
    "        self.layer4 = build_resblock(360, 720, 2)  # x:[b,720,7,7]\n",
    "\n",
    "        # 通过 Pooling 层将高宽降低为 1x1,[b,720,1,1]\n",
    "        self.avgpool = nn.AdaptiveAvgPool2D(1)\n",
    "        # 需要拉平为[b,720],不能直接输出连接线性层\n",
    "        self.flatten = nn.Flatten()\n",
    "        # 最后连接一个全连接层分类\n",
    "        self.fc = nn.Linear(in_features=720,out_features=num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # 前向计算函数：通过根网络\n",
    "        x = self.features(inputs)\n",
    "        # 一次通过 4 个模块\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        # 通过池化层\n",
    "        x = self.avgpool(x)\n",
    "        # 拉平\n",
    "        x = self.flatten(x)\n",
    "        # 通过全连接层\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# ResNet18网络\n",
    "model = ResNet18_1()\n",
    "# 可视化模型\n",
    "paddle.summary(model,(-1,1,28,28))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "   Layer (type)         Input Shape          Output Shape         Param #    \n",
      "===============================================================================\n",
      "     Conv2D-1         [[1, 1, 28, 28]]     [1, 64, 14, 14]         3,200     \n",
      "   BatchNorm2D-1     [[1, 64, 14, 14]]     [1, 64, 14, 14]          256      \n",
      "      ReLU-1         [[1, 64, 14, 14]]     [1, 64, 14, 14]           0       \n",
      "    MaxPool2D-1      [[1, 64, 14, 14]]      [1, 64, 7, 7]            0       \n",
      "     Conv2D-2         [[1, 64, 7, 7]]       [1, 64, 7, 7]         36,928     \n",
      "   BatchNorm2D-2      [[1, 64, 7, 7]]       [1, 64, 7, 7]           256      \n",
      "      ReLU-2          [[1, 64, 7, 7]]       [1, 64, 7, 7]            0       \n",
      "     Conv2D-3         [[1, 64, 7, 7]]       [1, 64, 7, 7]         36,928     \n",
      "   BatchNorm2D-3      [[1, 64, 7, 7]]       [1, 64, 7, 7]           256      \n",
      "    Residual-1        [[1, 64, 7, 7]]       [1, 64, 7, 7]            0       \n",
      "     Conv2D-4         [[1, 64, 7, 7]]       [1, 64, 7, 7]         36,928     \n",
      "   BatchNorm2D-4      [[1, 64, 7, 7]]       [1, 64, 7, 7]           256      \n",
      "      ReLU-3          [[1, 64, 7, 7]]       [1, 64, 7, 7]            0       \n",
      "     Conv2D-5         [[1, 64, 7, 7]]       [1, 64, 7, 7]         36,928     \n",
      "   BatchNorm2D-5      [[1, 64, 7, 7]]       [1, 64, 7, 7]           256      \n",
      "    Residual-2        [[1, 64, 7, 7]]       [1, 64, 7, 7]            0       \n",
      "     Conv2D-6         [[1, 64, 7, 7]]       [1, 150, 4, 4]        86,550     \n",
      "   BatchNorm2D-6      [[1, 150, 4, 4]]      [1, 150, 4, 4]          600      \n",
      "      ReLU-4          [[1, 150, 4, 4]]      [1, 150, 4, 4]           0       \n",
      "     Conv2D-7         [[1, 150, 4, 4]]      [1, 150, 4, 4]        202,650    \n",
      "   BatchNorm2D-7      [[1, 150, 4, 4]]      [1, 150, 4, 4]          600      \n",
      "     Conv2D-8         [[1, 64, 7, 7]]       [1, 150, 4, 4]         9,750     \n",
      "    Residual-3        [[1, 64, 7, 7]]       [1, 150, 4, 4]           0       \n",
      "     Conv2D-9         [[1, 150, 4, 4]]      [1, 150, 4, 4]        202,650    \n",
      "   BatchNorm2D-8      [[1, 150, 4, 4]]      [1, 150, 4, 4]          600      \n",
      "      ReLU-5          [[1, 150, 4, 4]]      [1, 150, 4, 4]           0       \n",
      "     Conv2D-10        [[1, 150, 4, 4]]      [1, 150, 4, 4]        202,650    \n",
      "   BatchNorm2D-9      [[1, 150, 4, 4]]      [1, 150, 4, 4]          600      \n",
      "    Residual-4        [[1, 150, 4, 4]]      [1, 150, 4, 4]           0       \n",
      "     Conv2D-11        [[1, 150, 4, 4]]      [1, 360, 2, 2]        486,360    \n",
      "  BatchNorm2D-10      [[1, 360, 2, 2]]      [1, 360, 2, 2]         1,440     \n",
      "      ReLU-6          [[1, 360, 2, 2]]      [1, 360, 2, 2]           0       \n",
      "     Conv2D-12        [[1, 360, 2, 2]]      [1, 360, 2, 2]       1,166,760   \n",
      "  BatchNorm2D-11      [[1, 360, 2, 2]]      [1, 360, 2, 2]         1,440     \n",
      "     Conv2D-13        [[1, 150, 4, 4]]      [1, 360, 2, 2]        54,360     \n",
      "    Residual-5        [[1, 150, 4, 4]]      [1, 360, 2, 2]           0       \n",
      "     Conv2D-14        [[1, 360, 2, 2]]      [1, 360, 2, 2]       1,166,760   \n",
      "  BatchNorm2D-12      [[1, 360, 2, 2]]      [1, 360, 2, 2]         1,440     \n",
      "      ReLU-7          [[1, 360, 2, 2]]      [1, 360, 2, 2]           0       \n",
      "     Conv2D-15        [[1, 360, 2, 2]]      [1, 360, 2, 2]       1,166,760   \n",
      "  BatchNorm2D-13      [[1, 360, 2, 2]]      [1, 360, 2, 2]         1,440     \n",
      "    Residual-6        [[1, 360, 2, 2]]      [1, 360, 2, 2]           0       \n",
      "     Conv2D-16        [[1, 360, 2, 2]]      [1, 720, 1, 1]       2,333,520   \n",
      "  BatchNorm2D-14      [[1, 720, 1, 1]]      [1, 720, 1, 1]         2,880     \n",
      "      ReLU-8          [[1, 720, 1, 1]]      [1, 720, 1, 1]           0       \n",
      "     Conv2D-17        [[1, 720, 1, 1]]      [1, 720, 1, 1]       4,666,320   \n",
      "  BatchNorm2D-15      [[1, 720, 1, 1]]      [1, 720, 1, 1]         2,880     \n",
      "     Conv2D-18        [[1, 360, 2, 2]]      [1, 720, 1, 1]        259,920    \n",
      "    Residual-7        [[1, 360, 2, 2]]      [1, 720, 1, 1]           0       \n",
      "     Conv2D-19        [[1, 720, 1, 1]]      [1, 720, 1, 1]       4,666,320   \n",
      "  BatchNorm2D-16      [[1, 720, 1, 1]]      [1, 720, 1, 1]         2,880     \n",
      "      ReLU-9          [[1, 720, 1, 1]]      [1, 720, 1, 1]           0       \n",
      "     Conv2D-20        [[1, 720, 1, 1]]      [1, 720, 1, 1]       4,666,320   \n",
      "  BatchNorm2D-17      [[1, 720, 1, 1]]      [1, 720, 1, 1]         2,880     \n",
      "    Residual-8        [[1, 720, 1, 1]]      [1, 720, 1, 1]           0       \n",
      "AdaptiveAvgPool2D-1   [[1, 720, 1, 1]]      [1, 720, 1, 1]           0       \n",
      "     Flatten-1        [[1, 720, 1, 1]]         [1, 720]              0       \n",
      "     Linear-1            [[1, 720]]            [1, 10]             7,210     \n",
      "===============================================================================\n",
      "Total params: 21,516,732\n",
      "Trainable params: 21,495,772\n",
      "Non-trainable params: 20,960\n",
      "-------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.06\n",
      "Params size (MB): 82.08\n",
      "Estimated Total Size (MB): 83.14\n",
      "-------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'total_params': 21516732, 'trainable_params': 21495772}"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# resnet 50"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import paddle\n",
    "import paddle.nn.functional as F # 组网相关的函数，如conv2d, relu...\n",
    "import numpy as np\n",
    "from paddle.nn.layer.common import Dropout \n",
    "from paddle.vision.transforms import Compose, Resize, Transpose, Normalize, ToTensor\n",
    "\n",
    "# 构建ResNet网络\n",
    "# Sequential：顺序容器，子Layer将按构造函数参数的顺序添加到此容器中，传递给构造函数的参数可以Layers或可迭代的name Layer元组\n",
    "from paddle.nn import Sequential, Conv2D, ReLU, MaxPool2D, Linear, Dropout, Flatten, BatchNorm2D, AvgPool2D\n",
    "\n",
    "#构建模型\n",
    "class Residual(paddle.nn.Layer):\n",
    "    def __init__(self, in_channel, out_channel, use_conv1x1=False, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2D(in_channel, out_channel, kernel_size=3, padding=1, stride=stride)\n",
    "        self.conv2 = Conv2D(out_channel, out_channel, kernel_size=3, padding=1)\n",
    "        if use_conv1x1: #使用1x1卷积核\n",
    "            self.conv3 = Conv2D(in_channel, out_channel, kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.batchNorm1 = BatchNorm2D(out_channel)\n",
    "        self.batchNorm2 = BatchNorm2D(out_channel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.batchNorm1(self.conv1(x)))\n",
    "        y = self.batchNorm2(self.conv2(y))\n",
    "        if self.conv3:\n",
    "            x = self.conv3(x)\n",
    "        out = F.relu(y+x) #核心代码\n",
    "        return out\n",
    "def ResNetBlock(in_channel, out_channel, num_layers, is_first=False):\n",
    "    if is_first:\n",
    "        assert in_channel == out_channel\n",
    "    block_list = []\n",
    "    for i in range(num_layers):\n",
    "        if i == 0 and not is_first:\n",
    "            block_list.append(Residual(in_channel, out_channel, use_conv1x1=True, stride=2))\n",
    "        else:\n",
    "            block_list.append(Residual(out_channel, out_channel))\n",
    "    resNetBlock = Sequential(*block_list) #用*号可以把list列表展开为元素\n",
    "    return resNetBlock\n",
    "\n",
    "class ResNet50(paddle.nn.Layer):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.b1 = Sequential(\n",
    "                    Conv2D(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "                    BatchNorm2D(64), \n",
    "                    ReLU(),\n",
    "                    MaxPool2D(kernel_size=3, stride=2, padding=1))\n",
    "        self.b2 = ResNetBlock(64, 64, 3, is_first=True)\n",
    "        self.b3 = ResNetBlock(64, 128, 4)\n",
    "        self.b4 = ResNetBlock(128, 256, 6)\n",
    "        self.b5 = ResNetBlock(256, 512, 3)\n",
    "        self.AvgPool = AvgPool2D(2)\n",
    "        self.flatten = Flatten()\n",
    "        self.Linear = Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.b1(x)\n",
    "        x = self.b2(x)\n",
    "        x = self.b3(x)\n",
    "        x = self.b4(x)\n",
    "        x = self.b5(x)\n",
    "        x = self.AvgPool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.Linear(x)\n",
    "        return x\n",
    "        \n",
    "resnet = ResNet50(num_classes=10)\n",
    "model = paddle.Model(resnet)\n",
    "from paddle.static import InputSpec\n",
    "input = InputSpec([None, 1, 28, 28], 'float32', 'image')\n",
    "label = InputSpec([None, 1], 'int64', 'label')\n",
    "model = paddle.Model(resnet, input, label)\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------------------------------------------------------------------------\n",
      " Layer (type)       Input Shape          Output Shape         Param #    \n",
      "===========================================================================\n",
      "   Conv2D-1       [[1, 1, 28, 28]]     [1, 64, 14, 14]         3,200     \n",
      " BatchNorm2D-1   [[1, 64, 14, 14]]     [1, 64, 14, 14]          256      \n",
      "    ReLU-1       [[1, 64, 14, 14]]     [1, 64, 14, 14]           0       \n",
      "  MaxPool2D-1    [[1, 64, 14, 14]]      [1, 64, 7, 7]            0       \n",
      "   Conv2D-2       [[1, 64, 7, 7]]       [1, 64, 7, 7]         36,928     \n",
      " BatchNorm2D-2    [[1, 64, 7, 7]]       [1, 64, 7, 7]           256      \n",
      "   Conv2D-3       [[1, 64, 7, 7]]       [1, 64, 7, 7]         36,928     \n",
      " BatchNorm2D-3    [[1, 64, 7, 7]]       [1, 64, 7, 7]           256      \n",
      "  Residual-1      [[1, 64, 7, 7]]       [1, 64, 7, 7]            0       \n",
      "   Conv2D-4       [[1, 64, 7, 7]]       [1, 64, 7, 7]         36,928     \n",
      " BatchNorm2D-4    [[1, 64, 7, 7]]       [1, 64, 7, 7]           256      \n",
      "   Conv2D-5       [[1, 64, 7, 7]]       [1, 64, 7, 7]         36,928     \n",
      " BatchNorm2D-5    [[1, 64, 7, 7]]       [1, 64, 7, 7]           256      \n",
      "  Residual-2      [[1, 64, 7, 7]]       [1, 64, 7, 7]            0       \n",
      "   Conv2D-6       [[1, 64, 7, 7]]       [1, 64, 7, 7]         36,928     \n",
      " BatchNorm2D-6    [[1, 64, 7, 7]]       [1, 64, 7, 7]           256      \n",
      "   Conv2D-7       [[1, 64, 7, 7]]       [1, 64, 7, 7]         36,928     \n",
      " BatchNorm2D-7    [[1, 64, 7, 7]]       [1, 64, 7, 7]           256      \n",
      "  Residual-3      [[1, 64, 7, 7]]       [1, 64, 7, 7]            0       \n",
      "   Conv2D-8       [[1, 64, 7, 7]]       [1, 128, 4, 4]        73,856     \n",
      " BatchNorm2D-8    [[1, 128, 4, 4]]      [1, 128, 4, 4]          512      \n",
      "   Conv2D-9       [[1, 128, 4, 4]]      [1, 128, 4, 4]        147,584    \n",
      " BatchNorm2D-9    [[1, 128, 4, 4]]      [1, 128, 4, 4]          512      \n",
      "   Conv2D-10      [[1, 64, 7, 7]]       [1, 128, 4, 4]         8,320     \n",
      "  Residual-4      [[1, 64, 7, 7]]       [1, 128, 4, 4]           0       \n",
      "   Conv2D-11      [[1, 128, 4, 4]]      [1, 128, 4, 4]        147,584    \n",
      "BatchNorm2D-10    [[1, 128, 4, 4]]      [1, 128, 4, 4]          512      \n",
      "   Conv2D-12      [[1, 128, 4, 4]]      [1, 128, 4, 4]        147,584    \n",
      "BatchNorm2D-11    [[1, 128, 4, 4]]      [1, 128, 4, 4]          512      \n",
      "  Residual-5      [[1, 128, 4, 4]]      [1, 128, 4, 4]           0       \n",
      "   Conv2D-13      [[1, 128, 4, 4]]      [1, 128, 4, 4]        147,584    \n",
      "BatchNorm2D-12    [[1, 128, 4, 4]]      [1, 128, 4, 4]          512      \n",
      "   Conv2D-14      [[1, 128, 4, 4]]      [1, 128, 4, 4]        147,584    \n",
      "BatchNorm2D-13    [[1, 128, 4, 4]]      [1, 128, 4, 4]          512      \n",
      "  Residual-6      [[1, 128, 4, 4]]      [1, 128, 4, 4]           0       \n",
      "   Conv2D-15      [[1, 128, 4, 4]]      [1, 128, 4, 4]        147,584    \n",
      "BatchNorm2D-14    [[1, 128, 4, 4]]      [1, 128, 4, 4]          512      \n",
      "   Conv2D-16      [[1, 128, 4, 4]]      [1, 128, 4, 4]        147,584    \n",
      "BatchNorm2D-15    [[1, 128, 4, 4]]      [1, 128, 4, 4]          512      \n",
      "  Residual-7      [[1, 128, 4, 4]]      [1, 128, 4, 4]           0       \n",
      "   Conv2D-17      [[1, 128, 4, 4]]      [1, 256, 2, 2]        295,168    \n",
      "BatchNorm2D-16    [[1, 256, 2, 2]]      [1, 256, 2, 2]         1,024     \n",
      "   Conv2D-18      [[1, 256, 2, 2]]      [1, 256, 2, 2]        590,080    \n",
      "BatchNorm2D-17    [[1, 256, 2, 2]]      [1, 256, 2, 2]         1,024     \n",
      "   Conv2D-19      [[1, 128, 4, 4]]      [1, 256, 2, 2]        33,024     \n",
      "  Residual-8      [[1, 128, 4, 4]]      [1, 256, 2, 2]           0       \n",
      "   Conv2D-20      [[1, 256, 2, 2]]      [1, 256, 2, 2]        590,080    \n",
      "BatchNorm2D-18    [[1, 256, 2, 2]]      [1, 256, 2, 2]         1,024     \n",
      "   Conv2D-21      [[1, 256, 2, 2]]      [1, 256, 2, 2]        590,080    \n",
      "BatchNorm2D-19    [[1, 256, 2, 2]]      [1, 256, 2, 2]         1,024     \n",
      "  Residual-9      [[1, 256, 2, 2]]      [1, 256, 2, 2]           0       \n",
      "   Conv2D-22      [[1, 256, 2, 2]]      [1, 256, 2, 2]        590,080    \n",
      "BatchNorm2D-20    [[1, 256, 2, 2]]      [1, 256, 2, 2]         1,024     \n",
      "   Conv2D-23      [[1, 256, 2, 2]]      [1, 256, 2, 2]        590,080    \n",
      "BatchNorm2D-21    [[1, 256, 2, 2]]      [1, 256, 2, 2]         1,024     \n",
      "  Residual-10     [[1, 256, 2, 2]]      [1, 256, 2, 2]           0       \n",
      "   Conv2D-24      [[1, 256, 2, 2]]      [1, 256, 2, 2]        590,080    \n",
      "BatchNorm2D-22    [[1, 256, 2, 2]]      [1, 256, 2, 2]         1,024     \n",
      "   Conv2D-25      [[1, 256, 2, 2]]      [1, 256, 2, 2]        590,080    \n",
      "BatchNorm2D-23    [[1, 256, 2, 2]]      [1, 256, 2, 2]         1,024     \n",
      "  Residual-11     [[1, 256, 2, 2]]      [1, 256, 2, 2]           0       \n",
      "   Conv2D-26      [[1, 256, 2, 2]]      [1, 256, 2, 2]        590,080    \n",
      "BatchNorm2D-24    [[1, 256, 2, 2]]      [1, 256, 2, 2]         1,024     \n",
      "   Conv2D-27      [[1, 256, 2, 2]]      [1, 256, 2, 2]        590,080    \n",
      "BatchNorm2D-25    [[1, 256, 2, 2]]      [1, 256, 2, 2]         1,024     \n",
      "  Residual-12     [[1, 256, 2, 2]]      [1, 256, 2, 2]           0       \n",
      "   Conv2D-28      [[1, 256, 2, 2]]      [1, 256, 2, 2]        590,080    \n",
      "BatchNorm2D-26    [[1, 256, 2, 2]]      [1, 256, 2, 2]         1,024     \n",
      "   Conv2D-29      [[1, 256, 2, 2]]      [1, 256, 2, 2]        590,080    \n",
      "BatchNorm2D-27    [[1, 256, 2, 2]]      [1, 256, 2, 2]         1,024     \n",
      "  Residual-13     [[1, 256, 2, 2]]      [1, 256, 2, 2]           0       \n",
      "   Conv2D-30      [[1, 256, 2, 2]]      [1, 512, 1, 1]       1,180,160   \n",
      "BatchNorm2D-28    [[1, 512, 1, 1]]      [1, 512, 1, 1]         2,048     \n",
      "   Conv2D-31      [[1, 512, 1, 1]]      [1, 512, 1, 1]       2,359,808   \n",
      "BatchNorm2D-29    [[1, 512, 1, 1]]      [1, 512, 1, 1]         2,048     \n",
      "   Conv2D-32      [[1, 256, 2, 2]]      [1, 512, 1, 1]        131,584    \n",
      "  Residual-14     [[1, 256, 2, 2]]      [1, 512, 1, 1]           0       \n",
      "   Conv2D-33      [[1, 512, 1, 1]]      [1, 512, 1, 1]       2,359,808   \n",
      "BatchNorm2D-30    [[1, 512, 1, 1]]      [1, 512, 1, 1]         2,048     \n",
      "   Conv2D-34      [[1, 512, 1, 1]]      [1, 512, 1, 1]       2,359,808   \n",
      "BatchNorm2D-31    [[1, 512, 1, 1]]      [1, 512, 1, 1]         2,048     \n",
      "  Residual-15     [[1, 512, 1, 1]]      [1, 512, 1, 1]           0       \n",
      "   Conv2D-35      [[1, 512, 1, 1]]      [1, 512, 1, 1]       2,359,808   \n",
      "BatchNorm2D-32    [[1, 512, 1, 1]]      [1, 512, 1, 1]         2,048     \n",
      "   Conv2D-36      [[1, 512, 1, 1]]      [1, 512, 1, 1]       2,359,808   \n",
      "BatchNorm2D-33    [[1, 512, 1, 1]]      [1, 512, 1, 1]         2,048     \n",
      "  Residual-16     [[1, 512, 1, 1]]      [1, 512, 1, 1]           0       \n",
      "  AvgPool2D-1     [[1, 512, 1, 1]]      [1, 512, 1, 1]           0       \n",
      "   Flatten-1      [[1, 512, 1, 1]]         [1, 512]              0       \n",
      "   Linear-1          [[1, 512]]            [1, 10]             5,130     \n",
      "===========================================================================\n",
      "Total params: 21,305,482\n",
      "Trainable params: 21,275,018\n",
      "Non-trainable params: 30,464\n",
      "---------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 81.27\n",
      "Estimated Total Size (MB): 82.59\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'total_params': 21305482, 'trainable_params': 21275018}"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. 模型配置与训练\n",
    "可以使用`Model`搭建实例，然后使用`model.prepare`接口进行模型的配置，比如优化器、损失函数和评价指标等，也可以使用其他方法配置和训练模型。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "BATCH_SIZE = 64\r\n",
    "train_loader = paddle.io.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE)\r\n",
    "test_loader = paddle.io.DataLoader(test_dataset, batch_size=BATCH_SIZE)\r\n",
    "# 为模型训练做准备，设置优化器，损失函数和精度计算方式\r\n",
    "learning_rate = 0.001\r\n",
    "loss_fn = paddle.nn.CrossEntropyLoss()\r\n",
    "opt = paddle.optimizer.Momentum(learning_rate=learning_rate, parameters=model.parameters(), momentum=0.9)\r\n",
    "model.prepare(optimizer=opt, loss=loss_fn, metrics=paddle.metric.Accuracy())\r\n",
    "log_dir = './log/resnet50_Mom'\r\n",
    "callback_train = paddle.callbacks.VisualDL(log_dir=log_dir)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **作业要求**：完成训练过程可视化的相关函数，训练模型并保存可视化结果。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "# 参数的分布图， 损失函数， acc 使用visualdl\r\n",
    "def DrawLossFunction():\r\n",
    "    pass\r\n",
    "# 启动模型训练，指定训练数据集，设置训练轮次，设置每次数据集计算的批次大小，设置日志格式\r\n",
    "model.fit(train_loader, test_loader, batch_size=64, epochs=50, eval_freq= 5, verbose=1, callbacks=callback_train, save_dir='./chk_points_resnet50_Mom/',save_freq=5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/50\n",
      "step 938/938 [==============================] - loss: 0.1064 - acc: 0.9971 - 36ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points_resnet50_Mom/0\n",
      "Eval begin...\n",
      "step 157/157 [==============================] - loss: 0.3793 - acc: 0.9105 - 20ms/step        \n",
      "Eval samples: 10000\n",
      "Epoch 2/50\n",
      "step 938/938 [==============================] - loss: 3.6569e-04 - acc: 0.9986 - 36ms/step      \n",
      "Epoch 3/50\n",
      "step 938/938 [==============================] - loss: 0.0094 - acc: 0.9989 - 37ms/step           \n",
      "Epoch 4/50\n",
      "step 938/938 [==============================] - loss: 1.4260e-04 - acc: 0.9993 - 36ms/step        \n",
      "Epoch 5/50\n",
      "step 938/938 [==============================] - loss: 7.0031e-04 - acc: 0.9995 - 35ms/step        \n",
      "Epoch 6/50\n",
      "step 938/938 [==============================] - loss: 9.6616e-05 - acc: 0.9995 - 36ms/step         \n",
      "save checkpoint at /home/aistudio/chk_points_resnet50_Mom/5\n",
      "Eval begin...\n",
      "step 157/157 [==============================] - loss: 0.3807 - acc: 0.9120 - 20ms/step        \n",
      "Eval samples: 10000\n",
      "Epoch 7/50\n",
      "step 938/938 [==============================] - loss: 4.5070e-04 - acc: 0.9997 - 35ms/step    \n",
      "Epoch 8/50\n",
      "step 938/938 [==============================] - loss: 3.8154e-04 - acc: 0.9996 - 35ms/step         \n",
      "Epoch 9/50\n",
      "step 938/938 [==============================] - loss: 5.9630e-05 - acc: 0.9997 - 36ms/step        \n",
      "Epoch 10/50\n",
      "step 938/938 [==============================] - loss: 0.0011 - acc: 0.9998 - 35ms/step            \n",
      "Epoch 11/50\n",
      "step 938/938 [==============================] - loss: 0.0020 - acc: 0.9998 - 35ms/step            \n",
      "save checkpoint at /home/aistudio/chk_points_resnet50_Mom/10\n",
      "Eval begin...\n",
      "step 157/157 [==============================] - loss: 0.4728 - acc: 0.9123 - 20ms/step        \n",
      "Eval samples: 10000\n",
      "Epoch 12/50\n",
      "step 938/938 [==============================] - loss: 4.1580e-04 - acc: 0.9999 - 35ms/step         \n",
      "Epoch 13/50\n",
      "step 938/938 [==============================] - loss: 2.9162e-05 - acc: 1.0000 - 38ms/step         \n",
      "Epoch 14/50\n",
      "step 938/938 [==============================] - loss: 6.3584e-04 - acc: 0.9999 - 36ms/step        \n",
      "Epoch 15/50\n",
      "step 938/938 [==============================] - loss: 2.3113e-05 - acc: 1.0000 - 36ms/step      \n",
      "Epoch 16/50\n",
      "step 938/938 [==============================] - loss: 5.2006e-04 - acc: 0.9999 - 36ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points_resnet50_Mom/15\n",
      "Eval begin...\n",
      "step 157/157 [==============================] - loss: 0.4659 - acc: 0.9124 - 20ms/step        \n",
      "Eval samples: 10000\n",
      "Epoch 17/50\n",
      "step 938/938 [==============================] - loss: 6.8307e-05 - acc: 0.9999 - 35ms/step        \n",
      "Epoch 18/50\n",
      "step 938/938 [==============================] - loss: 2.8207e-05 - acc: 0.9999 - 36ms/step         \n",
      "Epoch 19/50\n",
      "step 938/938 [==============================] - loss: 4.6816e-05 - acc: 0.9999 - 35ms/step        \n",
      "Epoch 20/50\n",
      "step 938/938 [==============================] - loss: 0.0010 - acc: 1.0000 - 35ms/step            \n",
      "Epoch 21/50\n",
      "step 938/938 [==============================] - loss: 7.8610e-04 - acc: 1.0000 - 35ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points_resnet50_Mom/20\n",
      "Eval begin...\n",
      "step 157/157 [==============================] - loss: 0.4859 - acc: 0.9126 - 20ms/step        \n",
      "Eval samples: 10000\n",
      "Epoch 22/50\n",
      "step 938/938 [==============================] - loss: 0.0122 - acc: 1.0000 - 36ms/step             \n",
      "Epoch 23/50\n",
      "step 938/938 [==============================] - loss: 1.5958e-05 - acc: 1.0000 - 35ms/step        \n",
      "Epoch 24/50\n",
      "step 938/938 [==============================] - loss: 0.0234 - acc: 0.9999 - 35ms/step            \n",
      "Epoch 25/50\n",
      "step 938/938 [==============================] - loss: 8.7317e-06 - acc: 1.0000 - 36ms/step        \n",
      "Epoch 26/50\n",
      "step 938/938 [==============================] - loss: 6.7251e-05 - acc: 1.0000 - 36ms/step         \n",
      "save checkpoint at /home/aistudio/chk_points_resnet50_Mom/25\n",
      "Eval begin...\n",
      "step 157/157 [==============================] - loss: 0.5169 - acc: 0.9134 - 20ms/step        \n",
      "Eval samples: 10000\n",
      "Epoch 27/50\n",
      "step 938/938 [==============================] - loss: 3.5534e-05 - acc: 1.0000 - 36ms/step        \n",
      "Epoch 28/50\n",
      "step 938/938 [==============================] - loss: 1.9884e-04 - acc: 1.0000 - 35ms/step        \n",
      "Epoch 29/50\n",
      "step 938/938 [==============================] - loss: 1.5209e-04 - acc: 1.0000 - 36ms/step         \n",
      "Epoch 30/50\n",
      "step 938/938 [==============================] - loss: 1.3938e-04 - acc: 1.0000 - 35ms/step        \n",
      "Epoch 31/50\n",
      "step 938/938 [==============================] - loss: 0.0011 - acc: 1.0000 - 35ms/step            \n",
      "save checkpoint at /home/aistudio/chk_points_resnet50_Mom/30\n",
      "Eval begin...\n",
      "step 157/157 [==============================] - loss: 0.4530 - acc: 0.9127 - 20ms/step        \n",
      "Eval samples: 10000\n",
      "Epoch 32/50\n",
      "step 938/938 [==============================] - loss: 4.1754e-04 - acc: 1.0000 - 36ms/step         \n",
      "Epoch 33/50\n",
      "step 938/938 [==============================] - loss: 0.0011 - acc: 1.0000 - 36ms/step            \n",
      "Epoch 34/50\n",
      "step 938/938 [==============================] - loss: 0.0035 - acc: 1.0000 - 37ms/step          \n",
      "Epoch 35/50\n",
      "step 938/938 [==============================] - loss: 7.9494e-06 - acc: 1.0000 - 37ms/step        \n",
      "Epoch 36/50\n",
      "step 938/938 [==============================] - loss: 8.1505e-05 - acc: 1.0000 - 36ms/step         \n",
      "save checkpoint at /home/aistudio/chk_points_resnet50_Mom/35\n",
      "Eval begin...\n",
      "step 157/157 [==============================] - loss: 0.5232 - acc: 0.9126 - 20ms/step        \n",
      "Eval samples: 10000\n",
      "Epoch 37/50\n",
      "step 938/938 [==============================] - loss: 1.5048e-05 - acc: 1.0000 - 35ms/step         \n",
      "Epoch 38/50\n",
      "step 938/938 [==============================] - loss: 1.0854e-04 - acc: 1.0000 - 36ms/step         \n",
      "Epoch 39/50\n",
      "step 938/938 [==============================] - loss: 8.6031e-05 - acc: 1.0000 - 35ms/step        \n",
      "Epoch 40/50\n",
      "step 938/938 [==============================] - loss: 2.0489e-07 - acc: 1.0000 - 35ms/step        \n",
      "Epoch 41/50\n",
      "step 938/938 [==============================] - loss: 0.0534 - acc: 1.0000 - 35ms/step             \n",
      "save checkpoint at /home/aistudio/chk_points_resnet50_Mom/40\n",
      "Eval begin...\n",
      "step 157/157 [==============================] - loss: 0.4294 - acc: 0.9122 - 20ms/step        \n",
      "Eval samples: 10000\n",
      "Epoch 42/50\n",
      "step 938/938 [==============================] - loss: 7.6664e-04 - acc: 1.0000 - 35ms/step        \n",
      "Epoch 43/50\n",
      "step 938/938 [==============================] - loss: 4.4791e-05 - acc: 1.0000 - 36ms/step         \n",
      "Epoch 44/50\n",
      "step 938/938 [==============================] - loss: 1.5604e-05 - acc: 1.0000 - 36ms/step        \n",
      "Epoch 45/50\n",
      "step 938/938 [==============================] - loss: 3.4813e-04 - acc: 1.0000 - 36ms/step        \n",
      "Epoch 46/50\n",
      "step 938/938 [==============================] - loss: 9.8720e-07 - acc: 1.0000 - 36ms/step       \n",
      "save checkpoint at /home/aistudio/chk_points_resnet50_Mom/45\n",
      "Eval begin...\n",
      "step 157/157 [==============================] - loss: 0.5517 - acc: 0.9124 - 20ms/step        \n",
      "Eval samples: 10000\n",
      "Epoch 47/50\n",
      "step 938/938 [==============================] - loss: 0.0016 - acc: 1.0000 - 35ms/step             \n",
      "Epoch 48/50\n",
      "step 938/938 [==============================] - loss: 4.9239e-04 - acc: 1.0000 - 35ms/step      \n",
      "Epoch 49/50\n",
      "step 938/938 [==============================] - loss: 3.2171e-05 - acc: 1.0000 - 36ms/step         \n",
      "Epoch 50/50\n",
      "step 938/938 [==============================] - loss: 2.3730e-06 - acc: 1.0000 - 37ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points_resnet50_Mom/final\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model.evaluate(test_dataset, verbose=1)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Eval begin...\n",
      "step 10000/10000 [==============================] - loss: 2.8610e-06 - acc: 0.9126 - 17ms/step         \n",
      "Eval samples: 10000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'loss': [2.8610189e-06], 'acc': 0.9126}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# from visualdl import LogWriter 可视化模型参数\n",
    "# params = model.parameters()\n",
    "# print(params)\n",
    "# labels = [str(i) for i in range(len(params))]\n",
    "#     # 初始化一个记录器\n",
    "# with LogWriter(logdir=\"./high_dimensional/\") as writer:\n",
    "#     # 将一组labels和对应的hot_vectors传入记录器进行记录\n",
    "#     writer.add_embeddings(tag='default',\n",
    "#                               metadata=labels,\n",
    "#                               mat=params)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.3 64-bit ('torch_3.6.3': pyenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "interpreter": {
   "hash": "328dc1e95799e67618d905377f310fe5aa234fc2f08c1eab05fb9c8357706382"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}