{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###  IMDB电影评论情感倾向分类\n",
    "\n",
    "**基于PaddlePaddle2.0基础API构建模型，利用互联网电影资料库Imdb数据来进行电影评论情感倾向预测。**\n",
    "\n",
    "\n",
    "*数据集简介：IMDB数据集是一个对电影评论标注为正向评论与负向评论的数据集，共有25000条文本数据作为训练集，25000条文本数据作为测试集。 该数据集的官方地址为： [http://ai.stanford.edu/~amaas/data/sentiment/](http://)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "import paddle\r\n",
    "\r\n",
    "#准备数据\r\n",
    "#加载IMDB数据\r\n",
    "imdb_train = paddle.text.datasets.Imdb(mode='train') #训练数据集\r\n",
    "imdb_test = paddle.text.datasets.Imdb(mode='test') #测试数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the:0\n",
      "and:1\n",
      "a:2\n",
      "of:3\n",
      "to:4\n",
      "...\n",
      "virtual:5143\n",
      "warriors:5144\n",
      "widely:5145\n",
      "<unk>:5146\n",
      "<pad>:5147\n",
      "totally 5148 words\n"
     ]
    }
   ],
   "source": [
    "#获取字典\n",
    "word_dict = imdb_train.word_idx\n",
    "\n",
    "#在字典中增加一个<pad>字符串\n",
    "word_dict['<pad>'] = len(word_dict)\n",
    "\n",
    "# 查看句子字典\n",
    "for k in list(word_dict)[:5]:\n",
    "    print(\"{}:{}\".format(k.decode('ASCII'), word_dict[k]))\n",
    "print(\"...\")\n",
    "for k in list(word_dict)[-5:]:\n",
    "    print(\"{}:{}\".format(k if isinstance(k, str) else k.decode('ASCII'), word_dict[k]))\n",
    "print(\"totally {} words\".format(len(word_dict)))\n",
    "\n",
    "#参数设定\n",
    "vocab_size = len(word_dict)\n",
    "embedding_size = 256\n",
    "hidden_size = 256\n",
    "n_layers = 2\n",
    "dropout = 0.5\n",
    "seq_len = 200\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "pad_id = word_dict['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence list id is: [5146, 43, 71, 6, 1092, 14, 0, 878, 130, 151, 5146, 18, 281, 747, 0, 5146, 3, 5146, 2165, 37, 5146, 46, 5, 71, 4089, 377, 162, 46, 5, 32, 1287, 300, 35, 203, 2136, 565, 14, 2, 253, 26, 146, 61, 372, 1, 615, 5146, 5, 30, 0, 50, 3290, 6, 2148, 14, 0, 5146, 11, 17, 451, 24, 4, 127, 10, 0, 878, 130, 43, 2, 50, 5146, 751, 5146, 5, 2, 221, 3727, 6, 9, 1167, 373, 9, 5, 5146, 7, 5, 1343, 13, 2, 5146, 1, 250, 7, 98, 4270, 56, 2316, 0, 928, 11, 11, 9, 16, 5, 5146, 5146, 6, 50, 69, 27, 280, 27, 108, 1045, 0, 2633, 4177, 3180, 17, 1675, 1, 2571]\n",
      "sentence label id is: 0\n",
      "--------------------------\n",
      "sentence list is:  <unk> has much in common with the third man another <unk> film set among the <unk> of <unk> europe like <unk> there is much inventive camera work there is an innocent american who gets emotionally involved with a woman he doesnt really understand and whose <unk> is all the more striking in contrast with the <unk> br but id have to say that the third man has a more <unk> storyline <unk> is a bit disjointed in this respect perhaps this is <unk> it is presented as a <unk> and making it too coherent would spoil the effect br br this movie is <unk> <unk> in more than one sense one never sees the sun shine grim but intriguing and frightening\n",
      "sentence label is:  negative\n"
     ]
    }
   ],
   "source": [
    "classes = ['negative', 'positive']\n",
    "\n",
    "# 生成句子列表\n",
    "def ids_to_str(ids):\n",
    "    # print(ids)\n",
    "    words = []\n",
    "    for k in ids:\n",
    "        w = list(word_dict)[k]\n",
    "        words.append(w if isinstance(w, str) else w.decode('ASCII'))\n",
    "    return \" \".join(words)\n",
    "\n",
    "# 取出来第一条数据看看样子。\n",
    "sent = imdb_train.docs[0]\n",
    "label = imdb_train.labels[0]\n",
    "print('sentence list id is:', sent)\n",
    "print('sentence label id is:', label)\n",
    "print('--------------------------')\n",
    "print('sentence list is: ', ids_to_str(sent))\n",
    "print('sentence label is: ', classes[label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 每个样本的单词数量不一样，用Padding使得每个样本输入大小为seq_len\r\n",
    "# 常见的处理方式是把数据集中的数据都统一成同样长度的数据。这包括：对于较长的数据进行截断处理，对于较短的数据用特殊的词<pad>进行填充。\r\n",
    "def padding(dataset):\r\n",
    "    padded_sents = []\r\n",
    "    labels = []\r\n",
    "    for batch_id, data in enumerate(dataset):\r\n",
    "        sent, label = data[0].astype('int64'), data[1].astype('int64')\r\n",
    "        padded_sent = np.concatenate([sent[:seq_len], [pad_id] * (seq_len - len(sent))]).astype('int64')\r\n",
    "        padded_sents.append(padded_sent)\r\n",
    "        labels.append(label)\r\n",
    "    return np.array(padded_sents), np.array(labels)\r\n",
    "\r\n",
    "train_x, train_y = padding(imdb_train)\r\n",
    "test_x, test_y = padding(imdb_test)\r\n",
    "    \r\n",
    "class IMDBDataset(paddle.io.Dataset):\r\n",
    "    def __init__(self, sents, labels):\r\n",
    "        self.sents = sents\r\n",
    "        self.labels = labels\r\n",
    "\r\n",
    "    def __getitem__(self, index):\r\n",
    "        data = self.sents[index]\r\n",
    "        label = self.labels[index]\r\n",
    "        return data, label\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.sents)\r\n",
    "\r\n",
    "train_dataset = IMDBDataset(train_x, train_y)\r\n",
    "test_dataset = IMDBDataset(test_x, test_y)\r\n",
    "\r\n",
    "train_loader = paddle.io.DataLoader(train_dataset, return_list=True, shuffle=True, batch_size=batch_size, drop_last=True)\r\n",
    "test_loader = paddle.io.DataLoader(test_dataset, return_list=True, shuffle=True, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 任务一：构建模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#构建模型\r\n",
    "import paddle.nn as nn\r\n",
    "\r\n",
    "class MyModel(paddle.nn.Layer):\r\n",
    "    def __init__(self):\r\n",
    "        super(MyModel, self).__init__()\r\n",
    "        self.embedding = nn.Embedding(vocab_size, 256)\r\n",
    "        self.gru = nn.GRU(256, 256, num_layers=2, direction='bidirectional', dropout=0.5)\r\n",
    "        self.dropout = nn.Dropout(0.5)\r\n",
    "        self.linear = nn.Linear(in_features=256*2, out_features=2)\r\n",
    "\r\n",
    "        \r\n",
    "    def forward(self, inputs):\r\n",
    "        emb = self.dropout(self.embedding(inputs))\r\n",
    "        output, hidden = self.gru(emb)\r\n",
    "        hidden = paddle.concat((hidden[-2,:,:], hidden[-1,:,:]), axis=1)\r\n",
    "        hidden = self.dropout(hidden)\r\n",
    "        return self.linear(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class Bow(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Bow, self).__init__()\n",
    "        self.emb = paddle.nn.Embedding(vocab_size, 256)\n",
    "        self.fc = paddle.nn.Linear(in_features=256, out_features=2)\n",
    "        self.dropout = paddle.nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = paddle.mean(x, axis=1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义一个用于情感分类的网络实例，SentimentClassifier\n",
    "class LSTM(paddle.nn.Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        # num_embeddings (int) - 嵌入字典的大小， input中的id必须满足 0 =< id < num_embeddings 。 。\n",
    "        # embedding_dim (int) - 每个嵌入向量的维度。\n",
    "        # padding_idx (int|long|None) - padding_idx的配置区间为 [-weight.shape[0], weight.shape[0]，如果配置了padding_idx，那么在训练过程中遇到此id时会被用\n",
    "        # sparse (bool) - 是否使用稀疏更新，在词嵌入权重较大的情况下，使用稀疏更新能够获得更快的训练速度及更小的内存/显存占用。\n",
    "        # weight_attr (ParamAttr|None) - 指定嵌入向量的配置，包括初始化方法，具体用法请参见 ParamAttr ，一般无需设置，默认值为None。\n",
    "        self.embedding = nn.Embedding(vocab_size, 256)\n",
    "\n",
    "        # input_size (int) - 输入的大小。\n",
    "        # hidden_size (int) - 隐藏状态大小。\n",
    "        # num_layers (int，可选) - 网络层数。默认为1。\n",
    "        # direction (str，可选) - 网络迭代方向，可设置为forward或bidirect（或bidirectional）。默认为forward。\n",
    "        # time_major (bool，可选) - 指定input的第一个维度是否是time steps。默认为False。\n",
    "        # dropout (float，可选) - dropout概率，指的是出第一层外每层输入时的dropout概率。默认为0。\n",
    "        # weight_ih_attr (ParamAttr，可选) - weight_ih的参数。默认为None。\n",
    "        # weight_hh_attr (ParamAttr，可选) - weight_hh的参数。默认为None。\n",
    "        # bias_ih_attr (ParamAttr，可选) - bias_ih的参数。默认为None。\n",
    "        # bias_hh_attr (ParamAttr，可选) - bias_hh的参数。默认为None。\n",
    "        self.lstm = nn.LSTM(256, 256, num_layers=2, direction='bidirectional',dropout=0.5)\n",
    "\n",
    "        # in_features (int) – 线性变换层输入单元的数目。\n",
    "        # out_features (int) – 线性变换层输出单元的数目。\n",
    "        # weight_attr (ParamAttr, 可选) – 指定权重参数的属性。默认值为None，表示使用默认的权重参数属性，将权重参数初始化为0。具体用法请参见 ParamAttr 。\n",
    "        # bias_attr (ParamAttr|bool, 可选) – 指定偏置参数的属性。 bias_attr 为bool类型且设置为False时，表示不会为该层添加偏置。 bias_attr 如果设置为True或者None，则表示使用默认的偏置参数属性，将偏置参数初始化为0。具体用法请参见 ParamAttr 。默认值为None。\n",
    "        # name (str，可选) – 具体用法请参见 Name ，一般无需设置，默认值为None。\n",
    "        self.linear = nn.Linear(in_features=256*2, out_features=2)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        emb = self.dropout(self.embedding(inputs))\n",
    "        \n",
    "        output, (hidden, _) = self.lstm(emb)\n",
    "        #output形状大小为[batch_size,seq_len,num_directions * hidden_size]\n",
    "        #hidden形状大小为[num_layers * num_directions, batch_size, hidden_size]\n",
    "        #把前向的hidden与后向的hidden合并在一起\n",
    "        hidden = paddle.concat((hidden[-2,:,:], hidden[-1,:,:]), axis = 1)\n",
    "        hidden = self.dropout(hidden)\n",
    "        #hidden形状大小为[batch_size, hidden_size * num_directions]\n",
    "        return self.linear(hidden) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# 构建自己的神经网络\n",
    "class RNN(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.emb = nn.Embedding(num_embeddings=vocab_size, embedding_dim=256)\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "        self.rnn = nn.SimpleRNN(input_size=256, hidden_size=256, num_layers=2, direction='forward', dropout=0.3)\n",
    "        self.linear = nn.Linear(256*2, 2)\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = self.drop1(x)\n",
    "        output, x = self.rnn(x)\n",
    "        x = paddle.concat((x[-2, :, :], x[-1, :, :]), axis=1)\n",
    "        x = self.drop2(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1114 16:36:34.330693  5169 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W1114 16:36:34.334748  5169 device_context.cc:372] device: 0, cuDNN Version: 7.6.\n"
     ]
    }
   ],
   "source": [
    "#封装模型\n",
    "model = MyModel()\n",
    "# model = Bow()\n",
    "# model = LSTM()\n",
    "# model = RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous step.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py:89: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if isinstance(slot[0], (np.ndarray, np.bool, numbers.Number)):\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 390/390 [==============================] - loss: 0.8537 - acc: 0.4993 - 22ms/step        \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 390/390 [==============================] - loss: 0.6954 - acc: 0.4960 - 9ms/step        \n",
      "Eval samples: 24960\n",
      "save checkpoint at model_params/best_model\n",
      "{'loss': [0.6954046], 'acc': 0.49603365384615383, 'step': 389, 'batch_size': 64}\n",
      "Epoch 2/10\n",
      "step 390/390 [==============================] - loss: 0.6878 - acc: 0.4948 - 20ms/step        \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 390/390 [==============================] - loss: 0.7087 - acc: 0.4998 - 9ms/step        \n",
      "Eval samples: 24960\n",
      "save checkpoint at model_params/best_model\n",
      "{'loss': [0.70869875], 'acc': 0.4997596153846154, 'step': 389, 'batch_size': 64}\n",
      "Epoch 3/10\n",
      "step 390/390 [==============================] - loss: 0.7225 - acc: 0.4997 - 20ms/step        \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 390/390 [==============================] - loss: 0.6995 - acc: 0.4958 - 9ms/step          \n",
      "Eval samples: 24960\n",
      "{'loss': [0.6994867], 'acc': 0.49583333333333335, 'step': 389, 'batch_size': 64}\n",
      "Epoch 4/10\n",
      "step 390/390 [==============================] - loss: 0.7209 - acc: 0.5036 - 21ms/step        \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 390/390 [==============================] - loss: 0.7235 - acc: 0.4935 - 10ms/step        \n",
      "Eval samples: 24960\n",
      "{'loss': [0.723459], 'acc': 0.4935096153846154, 'step': 389, 'batch_size': 64}\n",
      "Epoch 5/10\n",
      "step 390/390 [==============================] - loss: 0.7111 - acc: 0.5083 - 21ms/step        \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 390/390 [==============================] - loss: 0.7063 - acc: 0.5009 - 10ms/step        \n",
      "Eval samples: 24960\n",
      "save checkpoint at model_params/best_model\n",
      "{'loss': [0.70631456], 'acc': 0.5008814102564103, 'step': 389, 'batch_size': 64}\n",
      "Epoch 6/10\n",
      "step 390/390 [==============================] - loss: 0.7455 - acc: 0.5022 - 21ms/step        \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 390/390 [==============================] - loss: 0.6961 - acc: 0.4931 - 9ms/step        \n",
      "Eval samples: 24960\n",
      "{'loss': [0.6960518], 'acc': 0.49306891025641025, 'step': 389, 'batch_size': 64}\n",
      "Epoch 7/10\n",
      "step 390/390 [==============================] - loss: 0.6856 - acc: 0.4980 - 21ms/step        \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 390/390 [==============================] - loss: 0.6981 - acc: 0.5020 - 9ms/step        \n",
      "Eval samples: 24960\n",
      "save checkpoint at model_params/best_model\n",
      "{'loss': [0.69814223], 'acc': 0.501963141025641, 'step': 389, 'batch_size': 64}\n",
      "Epoch 8/10\n",
      "step 390/390 [==============================] - loss: 0.7157 - acc: 0.5020 - 21ms/step        \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 390/390 [==============================] - loss: 0.7047 - acc: 0.4913 - 9ms/step        \n",
      "Eval samples: 24960\n",
      "{'loss': [0.7046883], 'acc': 0.4912660256410256, 'step': 389, 'batch_size': 64}\n",
      "Epoch 9/10\n",
      "step 390/390 [==============================] - loss: 0.7097 - acc: 0.4976 - 21ms/step        \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 390/390 [==============================] - loss: 0.7258 - acc: 0.4990 - 10ms/step        \n",
      "Eval samples: 24960\n",
      "{'loss': [0.7257817], 'acc': 0.49903846153846154, 'step': 389, 'batch_size': 64}\n",
      "Epoch 10/10\n",
      "step 390/390 [==============================] - loss: 0.7030 - acc: 0.5006 - 21ms/step        \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 390/390 [==============================] - loss: 0.7035 - acc: 0.5008 - 10ms/step        \n",
      "Eval samples: 24960\n",
      "{'loss': [0.7035177], 'acc': 0.5008413461538461, 'step': 389, 'batch_size': 64}\n"
     ]
    }
   ],
   "source": [
    "\r\n",
    "model = paddle.Model(model) #用Model封装模型\r\n",
    "\r\n",
    "#配置模型优化器、损失函数、评估函数\r\n",
    "model.prepare(paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters()),\r\n",
    "              paddle.nn.CrossEntropyLoss(),\r\n",
    "              paddle.metric.Accuracy())\r\n",
    "\r\n",
    "# 自定义 存储最优模型参数 回调函数：\r\n",
    "class Best_model_checkpoint(paddle.callbacks.Callback):\r\n",
    "    def __init__(self, baseline=0, save_dir=None):\r\n",
    "        self.baseline = baseline\r\n",
    "        self.save_dir = save_dir\r\n",
    "\r\n",
    "    def on_eval_end(self, logs=None):\r\n",
    "        acc = logs['acc']\r\n",
    "        if acc > self.baseline:\r\n",
    "            self.baseline = acc\r\n",
    "            path = '{}/best_model'.format(self.save_dir)\r\n",
    "            print('save checkpoint at {}'.format(path))\r\n",
    "            self.model.save(path)\r\n",
    "        print(logs)\r\n",
    "\r\n",
    "plot_callback = paddle.callbacks.VisualDL(log_dir='visualdl_log_dir/RNN')\r\n",
    "best_model_checkpoint = Best_model_checkpoint(save_dir='model_params')  # 加入在线显示 曲线部分\r\n",
    "\r\n",
    "#模型训练\r\n",
    "model.fit(train_loader,test_loader,\r\n",
    "          epochs=epochs,\r\n",
    "          eval_freq=1,\r\n",
    "          batch_size=batch_size,\r\n",
    "          verbose=1,\r\n",
    "          callbacks=[plot_callback, best_model_checkpoint]\r\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 任务二：输出测试集的最好精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 390/390 [==============================] - acc: 0.5018 - 10ms/step        \n",
      "Eval samples: 24960\n"
     ]
    }
   ],
   "source": [
    "#模型评估\r\n",
    "# import os\r\n",
    "# print(os.getcwd())\r\n",
    "model_state_dict = paddle.load('model_params/best_model.pdparams')  # 导入最优模型\r\n",
    "# model = MyModel()\r\n",
    "model = RNN()\r\n",
    "\r\n",
    "model.set_state_dict(model_state_dict)\r\n",
    "model = paddle.Model(model)\r\n",
    "model.prepare(metrics=paddle.metric.Accuracy())\r\n",
    " \r\n",
    "eval_result = model.evaluate(test_loader, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file `./visualdl_log_dir/RNN/vdlrecords.1636878998.log`\n",
      "Uploading file `./visualdl_log_dir/GRU/vdlrecords.1636875463.log`\n",
      "Uploading file `./visualdl_log_dir/LSTM/vdlrecords.1636878910.log`\n",
      "Uploading file `./visualdl_log_dir/Bow/vdlrecords.1636874156.log`\n",
      "View your visualization results at: `https://paddlepaddle.org.cn/paddle/visualdl/service/app?id=8149280384c94fce7d09162da61e514b`.\n"
     ]
    }
   ],
   "source": [
    "!visualdl service upload --logdir ./visualdl_log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
